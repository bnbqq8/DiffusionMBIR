{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a8e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd2a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(48,1,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826eaaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 24, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x = x.permute(1,0,2,3).unsqueeze(0)\n",
    "F.interpolate(_x,scale_factor=(1/2,1,1), mode=\"nearest\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4a00144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, torch.Size([1, 256, 256]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]*2,x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45bcc3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 96,   1, 256, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_shape = x.shape\n",
    "torch.tensor([_shape[0]*2,*_shape[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b20fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    EnsureChannelFirstd,\n",
    "    Lambda,\n",
    "    LoadImaged,\n",
    "    ResizeWithPadOrCrop,\n",
    "    ScaleIntensityRangePercentilesd,\n",
    "    SqueezeDim,\n",
    ")\n",
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "        ScaleIntensityRangePercentilesd(\n",
    "            keys=[\"image\"], lower=0.1, upper=99.9, b_min=0.0, b_max=1.0, clip=False\n",
    "        ),\n",
    "        # CropForegroundd(\n",
    "        #     keys=[\"image\", \"mask\"],\n",
    "        #     source_key=\"mask\",\n",
    "        #     # margin=[0, 128, 128] if args.seq == \"T1\" else [128, 128, 0],\n",
    "        #     allow_smaller=True,\n",
    "        # ),\n",
    "        Lambda(func=lambda x: x[\"image\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56718ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        ScaleIntensityRangePercentilesd(\n",
    "            keys=[\"image\"], lower=0.1, upper=99.9, b_min=0.0, b_max=1.0, clip=False\n",
    "        ),\n",
    "        Lambda(func=lambda x: x[\"image\"]),\n",
    "    ]\n",
    ")\n",
    "path = \"/root/aicp-data/IXI_downsampledx2_iacl/IXI002-Guys-0828/T1.nii.gz\"\n",
    "mask_path = \"/root/aicp-data/IXI_downsampledx2_iacl/IXI002-Guys-0828/T1_mask.nii.gz\"\n",
    "data = transforms({\"image\": path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2c0b095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 256, 173])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e461247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjoint test: <A x, y> = -2289.725830078125 , <x, A^T y> = -2289.725341796875 , diff = 0.00048828125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def _A(x):\n",
    "    # return radon.A(x)\n",
    "    # return F.interpolate(\n",
    "    #     x, scale_factor=factor, mode=\"nearest\", align_corners=False\n",
    "    # )\n",
    "    indices = torch.arange(0, x.size(0), factor, device=x.device, dtype=torch.long)\n",
    "    return x.index_select(0, indices)\n",
    "\n",
    "def _AT(y):\n",
    "    # y: [Nsamp, C, H, W] or general [...], factor from outer scope\n",
    "    # target_shape = (y.shape[0] * factor, *y.shape[1:])  # tuple of ints, safe\n",
    "    target_shape = img_shape\n",
    "    x_hr = torch.zeros(target_shape, device=y.device, dtype=y.dtype)\n",
    "    indices = torch.arange(\n",
    "        0, target_shape[0], factor, device=y.device, dtype=torch.long\n",
    "    )\n",
    "    x_hr.index_copy_(0, indices, y)\n",
    "    return x_hr\n",
    "\n",
    "device = 'cuda'  # just keep device logic\n",
    "\n",
    "img_shape = (179,1,256,256)\n",
    "factor=2.0\n",
    "# 随机 x, y 维度需与 A/AT 对应\n",
    "x = torch.randn(img_shape, device='cuda' if torch.cuda.is_available() else 'cpu', dtype=torch.float32)\n",
    "y = torch.randn((int(img_shape[0]//factor)+1, *img_shape[1:]), device=x.device, dtype=x.dtype)\n",
    "\n",
    "Ax = _A(x)\n",
    "ATy = _AT(y)\n",
    "\n",
    "lhs = float((Ax.flatten() * y.flatten()).sum().cpu().numpy())\n",
    "rhs = float((x.flatten() * ATy.flatten()).sum().cpu().numpy())\n",
    "print(\"Adjoint test: <A x, y> =\", lhs, \", <x, A^T y> =\", rhs, \", diff =\", abs(lhs-rhs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5928cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero slice indices in x0_back: 44\n",
      "nonzero sums values (selected): 65536.0\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones_like(x).to(x.device)\n",
    "k = img_shape[0]//4\n",
    "x0 = torch.zeros(img_shape, device=ones.device)\n",
    "x0[k:k+1] = 1.0\n",
    "y0 = _A(x0)\n",
    "x0_back = _AT(y0)\n",
    "nonzero_sums = x0_back.abs().sum(dim=(1,2,3))\n",
    "nonzero_idx = (nonzero_sums > 1e-8).nonzero().squeeze().cpu().numpy()\n",
    "print(\"nonzero slice indices in x0_back:\", nonzero_idx)\n",
    "print(\"nonzero sums values (selected):\", nonzero_sums[nonzero_idx].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae1ac006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero slice indices in x0_back: 44\n",
      "nonzero sums values (selected): 65536.0\n"
     ]
    }
   ],
   "source": [
    "k = img_shape[0]//4\n",
    "x0 = torch.zeros(img_shape, device=ones.device)\n",
    "x0[k:k+1] = 1.0\n",
    "y0 = _A(x0)\n",
    "x0_back = _AT(y0)\n",
    "nonzero_sums = x0_back.abs().sum(dim=(1,2,3))\n",
    "nonzero_idx = (nonzero_sums > 1e-8).nonzero().squeeze().cpu().numpy()\n",
    "print(\"nonzero slice indices in x0_back:\", nonzero_idx)\n",
    "print(\"nonzero sums values (selected):\", nonzero_sums[nonzero_idx].cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de15952e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czfy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
